---
layout: default
title: Workshop Abstract
---

One of the ongoing questions in the development of intelligent learning systems is how to design models that smoothly negotiate the transition from low-level features of the data to high-level representations that are compositional, interpretable, and generalize well across examples. At lower levels of representation, connectionist models have proven highly effective at learning representations with good predictive accuracy. At higher levels of abstraction, where uncertainty about latent variables becomes more important, structured probabilistic models can be used to represent knowledge of  the world and prior information in a modular and composable manner. However, inference is typically a bottleneck in such models, and state-of-the-art methods have historically been model-specific, in the sense that they make use of assumptions that do not trivially apply or generalize to other models. 

In recent years, there has been a resurgence of interest in black box inference techniques that make relatively few assumptions about the structure of a model and therefore apply more generally. These techniques include black box variational inference, gradient estimators based on automatic differentiation, sequential Monte Carlo samplers, and the use of discriminative methods such as deep neural networks for inference amortization. As a result of these innovations, along with generic implementations of black box methods in probabilistic programming systems, it is now possible to explore the design of hybrid models that combine the scalability of discriminative models with the interpretability and compositionality of generative models. 

This workshop brings together developers of black box inference technologies, probabilistic programming systems, and connectionist learning architectures. The goal is to formulate an understanding of ways in which latent variable models can be scaled up by integrating generic probabilistic inference techniques with bottom-up discriminative techniques, with the goal of learning structured representations of data that are composable, interpretable, testable, and allow efficient inference at test time. 
